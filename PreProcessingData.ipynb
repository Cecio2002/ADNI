{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyONfW6djHVpM0iEl1pDsJPl"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["# STEP 1: Monta Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tgiiaQuuNXfE","executionInfo":{"status":"ok","timestamp":1747657417191,"user_tz":-120,"elapsed":16974,"user":{"displayName":"marco cecilia","userId":"00111664620548072619"}},"outputId":"3963aeb9-42fc-472b-c92e-2157030db820"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"-6JjgdiHLj29","executionInfo":{"status":"ok","timestamp":1747053246424,"user_tz":-120,"elapsed":10011,"user":{"displayName":"marco cecilia","userId":"00111664620548072619"}},"outputId":"f26e2379-14e6-4f05-ac4b-31dfcb250f55"},"outputs":[{"output_type":"stream","name":"stdout","text":["Reading package lists... Done\n","Building dependency tree... Done\n","Reading state information... Done\n","The following additional packages will be installed:\n","  libyaml-cpp0.7\n","The following NEW packages will be installed:\n","  dcm2niix libyaml-cpp0.7\n","0 upgraded, 2 newly installed, 0 to remove and 34 not upgraded.\n","Need to get 354 kB of archives.\n","After this operation, 1,231 kB of additional disk space will be used.\n","Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 libyaml-cpp0.7 amd64 0.7.0+dfsg-8build1 [97.7 kB]\n","Get:2 http://archive.ubuntu.com/ubuntu jammy/universe amd64 dcm2niix amd64 1.0.20211006-1build1 [256 kB]\n","Fetched 354 kB in 1s (318 kB/s)\n","debconf: unable to initialize frontend: Dialog\n","debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 2.)\n","debconf: falling back to frontend: Readline\n","debconf: unable to initialize frontend: Readline\n","debconf: (This frontend requires a controlling tty.)\n","debconf: falling back to frontend: Teletype\n","dpkg-preconfigure: unable to re-open stdin: \n","Selecting previously unselected package libyaml-cpp0.7:amd64.\n","(Reading database ... 126102 files and directories currently installed.)\n","Preparing to unpack .../libyaml-cpp0.7_0.7.0+dfsg-8build1_amd64.deb ...\n","Unpacking libyaml-cpp0.7:amd64 (0.7.0+dfsg-8build1) ...\n","Selecting previously unselected package dcm2niix.\n","Preparing to unpack .../dcm2niix_1.0.20211006-1build1_amd64.deb ...\n","Unpacking dcm2niix (1.0.20211006-1build1) ...\n","Setting up libyaml-cpp0.7:amd64 (0.7.0+dfsg-8build1) ...\n","Setting up dcm2niix (1.0.20211006-1build1) ...\n","Processing triggers for man-db (2.10.2-1) ...\n","Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\n","/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n","\n"]}],"source":["# STEP 2: Installa dcm2niix\n","!sudo apt-get install -y dcm2niix\n"]},{"cell_type":"code","source":["# STEP 3: Imposta le cartelle\n","import os\n","import glob\n","\n","# Directory principale con le cartelle ADNI\n","base_dir = \"/content/drive/MyDrive/app_project/mri_ultimostr\"\n","\n","# Directory unica di output\n","output_dir = \"/content/drive/MyDrive/NIFTI_OUTPUT_str\"\n","os.makedirs(output_dir, exist_ok=True)\n"],"metadata":{"id":"5X5LdZo9NdR1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# STEP 4: Scansione e conversione\n","import subprocess\n","import shutil  # Import shutil\n","\n","\n","# Cicla tutte le cartelle ADNI\n","for adni_folder in sorted(os.listdir(base_dir)):\n","    adni_path = os.path.join(base_dir, adni_folder)\n","    if not os.path.isdir(adni_path): continue\n","\n","    # Dentro ogni cartella ADNI c'√® una sola cartella: l'ID del paziente\n","    patient_folders = os.listdir(adni_path)\n","    for patient_id in patient_folders:\n","        mp_rage_path = os.path.join(adni_path, patient_id, \"MP-RAGE\")\n","        if not os.path.isdir(mp_rage_path): continue\n","\n","        # Ogni sotto-cartella √® una data\n","        for date_folder in os.listdir(mp_rage_path):\n","            dicom_path = os.path.join(mp_rage_path, date_folder)\n","            if not os.path.isdir(dicom_path): continue\n","\n","            # Output file name\n","            output_name = f\"{patient_id}_{date_folder.replace('/', '-')}\"  # Sicurezza nome file\n","            temp_output_dir = \"/content/temp_dcm2niix\"\n","            os.makedirs(temp_output_dir, exist_ok=True)\n","\n","            # Converti con dcm2niix\n","            subprocess.run([\n","                \"dcm2niix\",\n","                \"-z\", \"y\",                      # Comprime in .nii.gz\n","                \"-f\", output_name,             # Nome file finale\n","                \"-o\", temp_output_dir,         # Output temporaneo\n","                dicom_path\n","            ])\n","\n","            # Sposta il risultato nella cartella finale\n","            for file in os.listdir(temp_output_dir):\n","                if file.endswith(\".nii.gz\"):\n","                    shutil.move(  # Use shutil.move instead of os.rename\n","                        os.path.join(temp_output_dir, file),\n","                        os.path.join(output_dir, file)\n","                    )\n","            # Pulisci la cartella temporanea\n","            for f in os.listdir(temp_output_dir):\n","                os.remove(os.path.join(temp_output_dir, f))\n"],"metadata":{"id":"0t0qLOzMNkLX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["TRASFORMARE UN FILE STAT ESTRANDO LA COLONNA DI VOLUME_MM3"],"metadata":{"id":"pn8J4Ha5USNj"}},{"cell_type":"code","source":["import os\n","import pandas as pd\n","from collections import defaultdict\n","from datetime import datetime\n","\n","# Percorso principale\n","base_path = \"/content/drive/MyDrive/app_project/fastsurfer_seg\"\n","\n","# Dizionario: paziente -> lista di (data, volume_dict)\n","pazienti = defaultdict(list)\n","\n","# Per verificare strutture uniche per file\n","strutture_per_file = {\n","    \"aseg+DKT.stats\": set(),\n","    \"cerebellum.CerebNet.stats\": set(),\n","    \"hypothalamus.HypVINN.stats\": set()\n","}\n","\n","# Funzione per leggere file .stats\n","def leggi_stats(file_path, file_label):\n","    volume_dict = {}\n","    if not os.path.exists(file_path):\n","        return volume_dict\n","    with open(file_path, \"r\") as f:\n","        for line in f:\n","            if line.startswith(\"#\") or line.strip() == \"\":\n","                continue\n","            fields = line.split()\n","            if len(fields) >= 5:\n","                struct = fields[4]\n","                try:\n","                    volume = float(fields[3])\n","                    volume_dict[struct] = volume  # <-- senza prefisso nel nome colonna\n","                    strutture_per_file[file_label + \".stats\"].add(struct)  # <-- mantieni il prefisso solo per controllo\n","                except:\n","                    continue\n","    return volume_dict\n","\n","for folder_name in os.listdir(base_path):\n","    folder_path = os.path.join(base_path, folder_name)\n","    stats_dir = os.path.join(folder_path, \"stats\")\n","\n","    if not os.path.exists(stats_dir):\n","        continue\n","\n","    try:\n","        parts = folder_name.split(\"_\")\n","        patient_id = \"_\".join(parts[:3])  # es: 003_S_1122\n","        date_str = parts[3]\n","        date_obj = datetime.strptime(date_str, \"%Y-%m-%d\")\n","\n","        # Unisci tutti e tre i dizionari\n","        volume_dict = {}\n","        volume_dict.update(leggi_stats(os.path.join(stats_dir, \"aseg+DKT.stats\"), \"aseg+DKT\"))\n","        volume_dict.update(leggi_stats(os.path.join(stats_dir, \"cerebellum.CerebNet.stats\"), \"cerebellum.CerebNet\"))\n","        volume_dict.update(leggi_stats(os.path.join(stats_dir, \"hypothalamus.HypVINN.stats\"), \"hypothalamus.HypVINN\"))\n","\n","        if volume_dict:  # Solo se almeno uno dei tre √® stato letto con successo\n","            pazienti[patient_id].append((date_obj, volume_dict))\n","\n","    except Exception as e:\n","        print(f\"Errore in {folder_name}: {e}\")\n","        continue\n","\n","# Trova il massimo numero di visite\n","max_visite = max(len(v) for v in pazienti.values())\n","\n","# Per ogni posizione temporale (prima visita, seconda, ecc.)\n","visite_posizionali = defaultdict(list)\n","\n","for i in range(max_visite):\n","    dati_per_visita = {}\n","\n","    for pid, visite in pazienti.items():\n","        visite_sorted = sorted(visite, key=lambda x: x[0])\n","        if i < len(visite_sorted):\n","            data, vol_dict = visite_sorted[i]\n","            vol_dict[\"Data\"] = data.strftime(\"%Y-%m-%d\")\n","            dati_per_visita[pid] = vol_dict\n","\n","    df = pd.DataFrame.from_dict(dati_per_visita, orient=\"index\")\n","    df.index.name = \"Patient_ID\"\n","    colonne = ['Data'] + [c for c in df.columns if c != 'Data']\n","    df = df[colonne]\n","    visite_posizionali[f\"Visita_{i+1}\"] = df\n","\n","# Salva in Excel\n","excel_path = \"/content/volumi_temporali_final.xlsx\"\n","with pd.ExcelWriter(excel_path) as writer:\n","    for sheet_name, df in visite_posizionali.items():\n","        df.to_excel(writer, sheet_name=sheet_name)\n","\n","# Controllo di sovrapposizione delle strutture tra file\n","all_duplicates = False\n","labels = list(strutture_per_file.keys())\n","for i in range(len(labels)):\n","    for j in range(i+1, len(labels)):\n","        common = strutture_per_file[labels[i]].intersection(strutture_per_file[labels[j]])\n","        if common:\n","            print(f\"\\n‚ö†Ô∏è Colonne comuni tra {labels[i]} e {labels[j]}:\")\n","            for c in common:\n","                print(f\" - {c}\")\n","            all_duplicates = True\n","\n","if not all_duplicates:\n","    print(\"\\n‚úÖ Nessuna colonna in comune tra i tre file stats.\")\n","\n","# Scarica\n","from google.colab import files\n","files.download(excel_path)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":115},"id":"KA_zM7W7-06v","executionInfo":{"status":"ok","timestamp":1747296688802,"user_tz":-120,"elapsed":277922,"user":{"displayName":"marco cecilia","userId":"00111664620548072619"}},"outputId":"bdbdbf25-00c9-4e5c-8cc0-3f205eb777b0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","‚ö†Ô∏è Colonne comuni tra aseg+DKT.stats e cerebellum.CerebNet.stats:\n"," - Right-Cerebellum-Cortex\n"," - Left-Cerebellum-Cortex\n"," - Right-Cerebellum-White-Matter\n"," - Left-Cerebellum-White-Matter\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_2f9ad7d7-8b3f-422d-ac4a-48661313f520\", \"volumi_temporali_final.xlsx\", 171577)"]},"metadata":{}}]},{"cell_type":"markdown","source":["SELEZIONIAMO LE 70 FEATURE PIU RILEVANTI SECONDO LA LETTERATURA SCIENTIFICA\n"],"metadata":{"id":"SLH5T2eZGKRR"}},{"cell_type":"code","source":["# Definisci le strutture da estrarre\n","strutture_interesse = [\n","    'Left-Hippocampus', 'Right-Hippocampus', 'ctx-lh-entorhinal', 'ctx-rh-entorhinal', 'L-Fornix',\n","    'ctx-rh-posteriorcingulate', 'ctx-lh-posteriorcingulate', 'ctx-lh-parahippocampal', 'ctx-rh-parahippocampal',\n","    'R-Fornix', 'ctx-rh-superiortemporal', 'Left-Amygdala', 'Right-Amygdala', 'ctx-rh-middletemporal',\n","    'ctx-rh-fusiform', 'Left-Thalamus', 'Right-Thalamus', 'ctx-rh-insula', 'ctx-lh-insula',\n","    'ctx-lh-rostralanteriorcingulate', 'ctx-lh-fusiform', 'ctx-rh-inferiortemporal', 'ctx-lh-middletemporal',\n","    'ctx-lh-superiortemporal', 'ctx-lh-inferiortemporal', 'ctx-rh-rostralanteriorcingulate',\n","    'Left-Cerebral-White-Matter', 'Right-Cerebral-White-Matter', 'ctx-rh-precuneus', 'ctx-rh-supramarginal',\n","    'ctx-lh-precuneus', 'ctx-lh-parstriangularis', 'ctx-rh-isthmuscingulate', 'ctx-lh-caudalanteriorcingulate',\n","    'ctx-lh-isthmuscingulate', 'ctx-rh-parstriangularis', 'ctx-lh-supramarginal', 'ctx-rh-medialorbitofrontal',\n","    'ctx-lh-medialorbitofrontal', 'ctx-lh-inferiorparietal', 'ctx-rh-caudalanteriorcingulate',\n","    'ctx-lh-superiorfrontal', 'ctx-rh-superiorfrontal', 'ctx-rh-superiorparietal', 'ctx-rh-parsopercularis',\n","    'R-C.mammilare', 'L-C.mammilare', 'WM-Hypointensities', 'ctx-rh-inferiorparietal', 'ctx-lh-superiorparietal',\n","    'ctx-lh-parsopercularis', 'ctx-rh-caudalmiddlefrontal', 'ctx-rh-parsorbitalis', 'ctx-lh-transversetemporal',\n","    'ctx-rh-rostralmiddlefrontal', 'ctx-lh-rostralmiddlefrontal', 'CC_Anterior', 'CSF', 'ctx-lh-caudalmiddlefrontal',\n","    'ctx-rh-lateralorbitofrontal', 'ctx-lh-lateralorbitofrontal', 'ctx-lh-parsorbitalis', 'ctx-rh-transversetemporal',\n","    'Right-Inf-Lat-Vent', 'Third-Ventricle', '3rd-Ventricle', 'Right-Lateral-Ventricle',\n","    'Left-Lateral-Ventricle', 'Left-Inf-Lat-Vent', 'CC_Mid_Anterior', 'CC_Central'\n","]\n","\n","# Nuovo dizionario per i dati filtrati\n","visite_filtrate = {}\n","\n","for nome_visita, df in visite_posizionali.items():\n","    colonne_da_tenere = ['Data'] + [c for c in df.columns if c in strutture_interesse]\n","    df_filtrato = df[colonne_da_tenere]\n","    visite_filtrate[nome_visita] = df_filtrato\n","\n","# Salva in Excel\n","output_path = \"/content/strutture_selezionate_solo.xlsx\"\n","with pd.ExcelWriter(output_path) as writer:\n","    for nome_visita, df in visite_filtrate.items():\n","        df.to_excel(writer, sheet_name=nome_visita)\n","\n","# Download (opzionale in Colab)\n","from google.colab import files\n","files.download(output_path)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":16},"id":"fSSfNMgvE2A1","executionInfo":{"status":"ok","timestamp":1747297991353,"user_tz":-120,"elapsed":661,"user":{"displayName":"marco cecilia","userId":"00111664620548072619"}},"outputId":"055c54fe-7bb1-4ceb-9fdb-16c6e2ec71e5"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_d1891ede-4303-4602-88c7-177fabbaae83\", \"strutture_selezionate_solo.xlsx\", 87969)"]},"metadata":{}}]},{"cell_type":"markdown","source":["UNIAMO I DATASET PROVENTI DAI VALORI TABULARI E IL DATASET GNENOMICO\n"],"metadata":{"id":"OJ8boiQGGSME"}},{"cell_type":"code","source":["import pandas as pd\n","\n","# Percorsi dei file\n","genomic_file = \"/content/drive/MyDrive/app_project/genomic_dataset.xlsx\"\n","mri_file = \"/content/drive/MyDrive/app_project/Dataset_tabs.xlsx\"\n","output_file = \"/content/drive/MyDrive/app_project/Dataset_tabs+genomica.xlsx\"\n","\n","# Carica i dati genomici\n","df_genomic = pd.read_excel(genomic_file)\n","df_genomic.columns = df_genomic.columns.str.strip()  # Pulisce spazi bianchi se presenti\n","\n","# Carica tutti i fogli MRI\n","mri_data = pd.read_excel(mri_file, sheet_name=None)\n","\n","# Dizionario per i nuovi fogli combinati\n","merged_data = {}\n","\n","# Unisci i dati genomici a ciascun foglio MRI\n","for sheet_name, df_visita in mri_data.items():\n","    df_visita.columns = df_visita.columns.str.strip()  # Pulisce nomi colonne anche qui\n","    merged_df = pd.merge(df_visita, df_genomic, on=\"Subject_ID\", how=\"left\")\n","    merged_data[sheet_name] = merged_df\n","\n","# Scrivi il nuovo file Excel combinato\n","with pd.ExcelWriter(output_file) as writer:\n","    for sheet_name, df in merged_data.items():\n","        df.to_excel(writer, sheet_name=sheet_name, index=False)\n","\n","print(\"‚úÖ File combinato creato con successo:\", output_file)\n","\n","# Scarica da Colab\n","from google.colab import files\n","files.download(output_file)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":32},"id":"jZPvJ5gsGYez","executionInfo":{"status":"ok","timestamp":1747315633923,"user_tz":-120,"elapsed":958,"user":{"displayName":"marco cecilia","userId":"00111664620548072619"}},"outputId":"9fc6545c-8c67-4d5f-b12f-95eb60fd6a7c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["‚úÖ File combinato creato con successo: /content/drive/MyDrive/app_project/Dataset_tabs+genomica.xlsx\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_0d033d87-b1e9-4e3d-a72e-eb731c8d5dd1\", \"Dataset_tabs+genomica.xlsx\", 72271)"]},"metadata":{}}]},{"cell_type":"code","source":["# Lista per raccogliere i pazienti mancanti\n","pazienti_mancanti = {}\n","\n","for sheet_name, df in merged_data.items():\n","    # Seleziona pazienti con tutti valori genomici nulli\n","    # Esclude la colonna 'Subject_ID' e controlla solo le colonne genomiche\n","    genomics_columns = df.columns.difference(df.columns[:df.columns.get_loc('Subject_ID') + 1])\n","    missing = df[df[genomics_columns].isnull().all(axis=1)][\"Subject_ID\"].tolist()\n","\n","    if missing:\n","        pazienti_mancanti[sheet_name] = missing\n","\n","# Stampa risultati\n","if pazienti_mancanti:\n","    print(\"‚ö†Ô∏è I seguenti pazienti non hanno dati genomici associati:\")\n","    for sheet, patients in pazienti_mancanti.items():\n","        print(f\"- {sheet}: {len(patients)} pazienti mancanti\")\n","        print(\"  \", patients)\n","else:\n","    print(\"‚úÖ Tutti i pazienti hanno dati genomici associati.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"O3dVYKzyJAv1","executionInfo":{"status":"ok","timestamp":1747315857143,"user_tz":-120,"elapsed":43,"user":{"displayName":"marco cecilia","userId":"00111664620548072619"}},"outputId":"1d58068b-a19f-4712-caee-59974f5a7535"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["‚úÖ Tutti i pazienti hanno dati genomici associati.\n"]}]},{"cell_type":"markdown","source":["CONCATENO I DUE CAZZI DI FILE DI GENOMIC IN UNICO FILE"],"metadata":{"id":"qfA6i19CJA_6"}},{"cell_type":"code","source":["# Step 1: Carica le librerie\n","import pandas as pd\n","\n","df1 =  pd.read_excel(\"/content/drive/MyDrive/app_project/genomic_dataset.xlsx\")\n","df2 =  pd.read_excel(\"/content/drive/MyDrive/app_project/genomic_dataset_2.xlsx\")\n","\n","# Estrai i nomi delle colonne\n","cols1 = set(df1.columns)\n","cols2 = set(df2.columns)\n","\n","# Trova colonne comuni e differenze\n","common_cols = cols1 & cols2\n","only_in_df1 = cols1 - cols2\n","only_in_df2 = cols2 - cols1\n","\n","# Stampa i risultati\n","print(\"‚úÖ Colonne in comune:\")\n","print(sorted(common_cols))\n","\n","print(\"\\n‚ùå Colonne presenti solo in genomic_dataset.xlsx:\")\n","print(sorted(only_in_df1))\n","\n","print(\"\\n‚ùå Colonne presenti solo in genomic_dataset_2.xlsx:\")\n","print(sorted(only_in_df2))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HaMm5GQRH2lI","executionInfo":{"status":"ok","timestamp":1747651685384,"user_tz":-120,"elapsed":1222,"user":{"displayName":"marco cecilia","userId":"00111664620548072619"}},"outputId":"02eeb265-f0b5-4557-9171-3cf55fd992b4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["‚úÖ Colonne in comune:\n","['Subject_ID', 'rs11136000_T', 'rs11767557_C', 'rs11771145_A', 'rs17125944_C', 'rs3764650_G', 'rs3851179_A', 'rs3865444_T', 'rs610932_A', 'rs744373_C']\n","\n","‚ùå Colonne presenti solo in genomic_dataset.xlsx:\n","['rs190982_G', 'rs7412_T']\n","\n","‚ùå Colonne presenti solo in genomic_dataset_2.xlsx:\n","[]\n"]}]},{"cell_type":"code","source":["\n","# Trova le colonne comuni\n","common_cols = list(set(df1.columns) & set(df2.columns))\n","\n","# Ordina le colonne nello stesso ordine di df1\n","common_cols_sorted = [col for col in df1.columns if col in common_cols]\n","\n","# Seleziona solo le colonne comuni con ordine coerente\n","df1_common = df1[common_cols_sorted]\n","df2_common = df2[common_cols_sorted]\n","\n","# Concatena\n","df_combined = pd.concat([df1_common, df2_common], ignore_index=True)\n","\n","# Salva il risultato\n","output_file = 'genomic_dataset_combined_common_columns.xlsx'\n","df_combined.to_excel(output_file, index=False)\n","\n","print(f\"‚úÖ File combinato salvato come '{output_file}' con {len(df_combined)} righe e {len(common_cols_sorted)} colonne comuni.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0NmPUfUwJwnd","executionInfo":{"status":"ok","timestamp":1747651776758,"user_tz":-120,"elapsed":445,"user":{"displayName":"marco cecilia","userId":"00111664620548072619"}},"outputId":"269df24d-cc92-4c02-81cf-4468a7674b17"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["‚úÖ File combinato salvato come 'genomic_dataset_combined_common_columns.xlsx' con 3017 righe e 10 colonne comuni.\n"]}]},{"cell_type":"markdown","source":["PASSO FINALE PER AVERE IL DATASET COMPLETO DI RISONANZE MAGNETICHE E DATI GENETICI DEL PAZIENTE\n"],"metadata":{"id":"Tk6Bb_zxMR_T"}},{"cell_type":"code","source":["import pandas as pd\n","\n","# === Step 1: Carica i file ===\n","\n","alz_dict =  pd.read_excel(\"/content/drive/MyDrive/app_project/Alzhameir_dataset.xlsx\", sheet_name=None)\n","gene_df =  pd.read_excel(\"/content/drive/MyDrive/app_project/Gene_dataset.xlsx\")\n","\n","\n","# === Step 2: Rimuovi duplicati nel Gene_dataset ===\n","gene_df = gene_df.drop_duplicates(subset='Subject_ID')\n","\n","# === Step 3: Verifica che tutti gli Subject_ID siano presenti anche nel Gene_dataset ===\n","gene_subject_ids = set(gene_df['Subject_ID'])\n","\n","missing_ids_total = {}\n","\n","for sheet_name, df in alz_dict.items():\n","    alz_subject_ids = set(df['Subject_ID'])\n","    missing_ids = alz_subject_ids - gene_subject_ids\n","    if missing_ids:\n","        missing_ids_total[sheet_name] = missing_ids\n","\n","if missing_ids_total:\n","    print(\"‚ùå Alcuni Subject_ID nei fogli Alzheimer NON sono presenti nel Gene_dataset:\")\n","    for sheet, ids in missing_ids_total.items():\n","        print(f\" - Foglio '{sheet}': {len(ids)} mancanti\")\n","    # Se vuoi forzare il merge anche con soggetti mancanti, puoi farlo aggiungendo `how='left'` pi√π avanti\n","else:\n","    print(\"‚úÖ Tutti i Subject_ID nei fogli Alzheimer sono presenti nel Gene_dataset.\")\n","\n","    # === Step 4: Esegui il merge per ogni foglio ===\n","    updated_sheets = {}\n","\n","    for sheet_name, df in alz_dict.items():\n","        merged_df = df.merge(gene_df, on='Subject_ID', how='left')\n","        updated_sheets[sheet_name] = merged_df\n","\n","    # === Step 5: Salva in un nuovo file Excel con tutti i fogli aggiornati ===\n","    output_file = 'Alzhameir_dataset_with_genes.xlsx'\n","    with pd.ExcelWriter(output_file) as writer:\n","        for sheet_name, df in updated_sheets.items():\n","            df.to_excel(writer, sheet_name=sheet_name, index=False)\n","\n","    print(f\"\\n‚úÖ File salvato come '{output_file}' con le feature genetiche aggiunte.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wEXv0qRcfkGX","executionInfo":{"status":"ok","timestamp":1747657427277,"user_tz":-120,"elapsed":5238,"user":{"displayName":"marco cecilia","userId":"00111664620548072619"}},"outputId":"2572bc4c-0381-4356-f8b9-89df3ee8528c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["‚úÖ Tutti i Subject_ID nei fogli Alzheimer sono presenti nel Gene_dataset.\n","\n","‚úÖ File salvato come 'Alzhameir_dataset_with_genes.xlsx' con le feature genetiche aggiunte.\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","\n","# === Step 1: Carica il file gi√† unito (con dati genetici) ===\n","alz_dict =  pd.read_excel(\"/content/drive/MyDrive/app_project/Alzhemeir_Dataset.xlsx\", sheet_name=None)\n","\n","# === Step 2: Aggiungi colonna per ordinare le visite ===\n","visit_order = list(alz_dict.keys())\n","for i, sheet in enumerate(visit_order):\n","    alz_dict[sheet]['__Visit_Order__'] = i  # serve per ordinare temporalmente\n","\n","# === Step 3: Unisci i fogli in un unico DataFrame ===\n","df_all = pd.concat(alz_dict.values(), ignore_index=True)\n","\n","# === Step 4: Ordina per paziente e visita\n","df_all_sorted = df_all.sort_values(by=['Subject_ID', '__Visit_Order__']).copy()\n","\n","# === Step 5: Individua solo le colonne numeriche con NaN\n","num_cols_with_nan = [col for col in df_all_sorted.select_dtypes(include='number').columns\n","                     if df_all_sorted[col].isna().any() and col != '__Visit_Order__']\n","\n","print(f\"üîç Colonne numeriche con valori mancanti da interpolare: {num_cols_with_nan}\")\n","\n","# === Step 6: Interpolazione SOLO dove serve, SOLO per quei pazienti e colonne ===\n","for col in num_cols_with_nan:\n","    df_all_sorted[col] = df_all_sorted.groupby('Subject_ID')[col].transform(\n","        lambda group: group.interpolate(method='linear', limit_direction='both')\n","    )\n","\n","# === Step 7: Ricostruisci i fogli originali ===\n","final_sheets = {}\n","for i, sheet_name in enumerate(visit_order):\n","    df_sheet = df_all_sorted[df_all_sorted['__Visit_Order__'] == i].drop(columns='__Visit_Order__')\n","    final_sheets[sheet_name] = df_sheet.reset_index(drop=True)\n","\n","# === Step 8: Salva il file Excel finale ===\n","output_file = 'Alzhameir_dataset_with_genes_interpolated.xlsx'\n","with pd.ExcelWriter(output_file) as writer:\n","    for sheet_name, df in final_sheets.items():\n","        df.to_excel(writer, sheet_name=sheet_name, index=False)\n","\n","print(f\"\\n‚úÖ Interpolazione completata SOLO sui valori nulli. File salvato come '{output_file}'.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6wxBneCGjshP","executionInfo":{"status":"ok","timestamp":1747658465459,"user_tz":-120,"elapsed":2753,"user":{"displayName":"marco cecilia","userId":"00111664620548072619"}},"outputId":"6e724bfd-3107-4b0b-a64a-0d2a1a7633de"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["üîç Colonne numeriche con valori mancanti da interpolare: ['L-Fornix', 'R-Fornix', 'R-C.mammilare', 'L-C.mammilare', 'Third-Ventricle']\n","\n","‚úÖ Interpolazione completata SOLO sui valori nulli. File salvato come 'Alzhameir_dataset_with_genes_interpolated.xlsx'.\n"]}]}]}